---
title: "Final data ingest and analysis"
author: "Abby Lewis"
date: "10/29/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(googlesheets4)
library(googledrive)
library(tidyverse)
library(lubridate)
library(colorspace)
```

TO DO:
- Add journal to complete_dataset file
- Delete the section that loads and formats data

Papers per year
```{r}
complete_forecasts <- read.csv("../Data/complete_dataset_with_source.csv") #Load data

#Plot the number of papers published per year
jpeg("../Figures/Pubs_year_noEco.jpeg", width = 7, height = 6, units = "in",res = 300)
complete_forecasts%>%
  ggplot()+
  geom_histogram(aes(x = Year),binwidth = 1)+
  xlim(1930,2020)+
  theme_bw()+
  xlab("Year")+
  ylab("Number of near-term ecological forecasts")+
  ylim(0,25)
dev.off()
```

Uncertainty type statistics
```{r}
complete_forecasts[complete_forecasts$Forecast_eval== "1",]
complete_forecasts$Uncert_source[complete_forecasts$Uncert_category == "no"] <- NA
complete_forecasts$Driver <- grepl("driver|meteo", complete_forecasts$Uncert_source, ignore.case = T)*1
complete_forecasts$Process <- grepl("process", complete_forecasts$Uncert_source, ignore.case = T)*1
complete_forecasts$Param <- grepl("param", complete_forecasts$Uncert_source, ignore.case = T)*1
complete_forecasts$IC <- grepl("init|ic", complete_forecasts$Uncert_source, ignore.case = T)*1
complete_forecasts$Obs <- grepl("obs", complete_forecasts$Uncert_source, ignore.case = T)*1

complete_forecasts%>%
  filter(!Uncert_category=="no")%>%
  summarize(driv = sum(Driver)/n(),
            proc = sum(Process)/n(),
            param = sum(Param)/n(),
            ic = sum(IC)/n(),
            obs = sum(Obs)/n())
```

Most common variables (statistics for paper)
```{r}
complete_forecasts$Vars_ident[grepl("ET |evap",complete_forecasts$Vars_ident,ignore.case = T)]
complete_forecasts$Vars_ident[grepl("pollen",complete_forecasts$Vars_ident,ignore.case = T)]
complete_forecasts$Vars_ident[grepl("diatom|cyano|oscillatoria|asterionella|desmus|anab|aphaniz|synecho|cyclo|stephanodiscus|raciborskii|circinale",complete_forecasts$Vars_ident, ignore.case = T)]
complete_forecasts$Vars_ident[grepl("chl",complete_forecasts$Vars_ident, ignore.case = T)]
complete_forecasts$Vars_ident[grepl("alg|hab |phyto",complete_forecasts$Vars_ident, ignore.case = T)]
complete_forecasts$Vars_ident[!grepl("yield",complete_forecasts$Vars_ident, ignore.case = T)]
complete_forecasts$Vars_ident[grepl("catch|fish|pollock|salmon|anchovy|walleye|herring|trout|carp",complete_forecasts$Vars_ident, ignore.case = T)] #except not lobster catch, shellfish harvesting, rusty crayfish distribution
```

Journals and languages represented
```{r}
length(unique(journals$Source)) #114 different journals
```

Map
```{r}
complete_forecasts <- read.csv("../Data/complete_dataset_with_source.csv")
WorldData <- map_data('world') %>% 
  fortify()
safe_colorblind_palette <- c("#661100", "#AA4499", "#DDCC77", "#117733","#44AA99","#999933","#332288", "#88CCEE", "#CC6677","#888888")


for_map <- complete_forecasts
coords <- for_map$Coords
for(i in 1:(max(str_count(for_map$Coords, ";"), na.rm = T)+1)){
  stops <- regexpr(pattern = ";",coords)
  stops[stops == -1] <- 10000L
  coords_i <- substr(coords, start = 1, stop = stops-1)
  for_map[nchar(coords_i)>0&!is.na(coords_i), paste0("Long",i)] <- as.numeric(sub("-*[0-9]+.[0-9]+,","",coords_i))[nchar(coords_i)>0&!is.na(coords_i)]
  for_map[nchar(coords_i)>0&!is.na(coords_i), paste0("Lat",i)] <- as.numeric(sub(", -*[0-9]+.[0-9]+","",coords_i))[nchar(coords_i)>0&!is.na(coords_i)]
  inds <- regexpr(pattern = ";",coords)
  inds[inds == -1]<-NA
  coords <- substr(coords, start = inds + 2, stop = 10000L)
}

for_map2 = for_map%>%
  pivot_longer(cols = num_range("Lat", 1:max(str_count(for_map$Coords, ";")+1, na.rm = T)), names_to = "Lat_num", values_to= "Lat")%>%
  pivot_longer(cols = num_range("Long", 1:max(str_count(for_map$Coords, ";")+1, na.rm = T)), names_to = "Long_num", values_to = "Long")%>%
  filter(sub("[a-z]+","",Lat_num)==sub("[a-z]+","",Long_num, ""))%>%
  filter(!Spat_scale == "global")

colors = lighten(safe_colorblind_palette, amount = .2)

for_map2$Region <- NA
for_map2$Region[for_map2$Spat_scale %in% c("regional","national")] <- 1
for_map2$Region[for_map2$Spat_scale %in% c("point","multipoint")]<-0

map <- ggplot() +
  geom_map(data = WorldData, map = WorldData,
                  aes(map_id=region),
                  fill = "white", colour = "#7f7f7f", size=0.5)+
  coord_map("rectangular", lat0=0, xlim=c(-180,180))+
  geom_point(data = for_map2%>%filter(Region == 1), aes(Long, Lat, fill = Ecosystem), shape = 21, color = "white", show.legend = F, size = 8, alpha  =.3, stroke = .5)+
  geom_point(data = for_map2%>%filter(Region == 0), aes(Long, Lat, fill = Ecosystem), shape = 21, color = "white", show.legend = F, size = 4, alpha  =1, stroke = .5)+
  theme_bw() + xlab(NULL) + ylab(NULL) +
  scale_fill_manual(breaks = c("agricultural", "atmosphere", "desert", "forest", "freshwater", "grassland", "marine", "tundra", "urban", "other", "NA"), values = colors, na.translate = T, na.value = "grey50", name = "Ecosystem")+
  theme(
    plot.background = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    axis.ticks = element_blank(),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    legend.position = "bottom",
    legend.direction = "horizontal")+
  guides(fill = F)


complete_forecasts$Ecosystem[is.na(complete_forecasts$Ecosystem)]<-"NA"
complete_forecasts$Ecosystem <- factor(complete_forecasts$Ecosystem, levels = c("agricultural","desert","grassland","forest","atmosphere","freshwater","marine","tundra","urban","other","NA"))
complete_forecasts$Spat_scale<- factor(complete_forecasts$Spat_scale, levels = c("point","multipoint","regional","national","global"))
extent <- complete_forecasts%>%
  ggplot(aes(x = Spat_scale, fill = Ecosystem))+
  scale_fill_manual(breaks = c("agricultural", "atmosphere", "desert", "forest", "freshwater", "grassland", "marine", "tundra", "urban", "other", "NA"), values = colors, na.translate = T, na.value = "grey50", name = "Ecosystem")+
  xlab("Spatial extent")+
  geom_bar(show.legend = F)+
  ylab("Number of papers")+
  theme_light()

class <- complete_forecasts%>%
  ggplot(aes(x = Class, fill = Ecosystem))+
  geom_bar()+
  scale_fill_manual(breaks = c("agricultural", "atmosphere", "desert", "forest", "freshwater", "grassland", "marine", "tundra", "urban", "other", "NA"), values = colors, na.translate = T, na.value = "grey50", name = "Ecosystem",guide = guide_legend(ncol = 2))

g_legend<-function(a.gplot){
  tmp <- ggplot_gtable(ggplot_build(a.gplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)}

legend_fill <- g_legend(class)

class <- complete_forecasts%>%
  ggplot(aes(x = Class, fill = Ecosystem))+
  geom_bar(show.legend = F)+
  scale_fill_manual(breaks = c("agricultural", "atmosphere", "desert", "forest", "freshwater", "grassland", "marine", "tundra", "urban", "other", "NA"), values = colors, na.translate = T, na.value = "grey50", name = "Ecosystem")+
  ylab("Number of papers")+
  theme_light()

library(ggpubr)
jpeg("../Figures/Map_composite.jpeg",width = 9, height = 6, units = "in", res = 300)
ggarrange(map, ggarrange(extent, class, legend_fill, labels = c("B","C"), label.y = c(1.2,1.2), nrow = 1, widths = c(1,1,.7)),nrow = 2, heights = c(6,3), labels = "A")
dev.off()

### Summary statistics
north_analysis <- for_map2$Lat[!is.na(for_map2$Lat)]
sum(north_analysis>0)/length(north_analysis)
sum(complete_forecasts$Spat_scale=="regional")/nrow(complete_forecasts)
sum(complete_forecasts$Class=="organismal"|complete_forecasts$Class=="both")/nrow(complete_forecasts)
sum(complete_forecasts$Ecosystem=="agricultural")/nrow(complete_forecasts)
```

Logistic regression
```{r}
complete_forecasts <- read.csv("../Data/complete_dataset_with_source.csv")
complete_forecasts$it_no_update_ic <- complete_forecasts$Iterative_yn==1&!complete_forecasts$DA_type%in%c("update IC","autoregressive, so new observed data become predictors for the next timestep","UNK","NA","autoregressive, uses previous observations to predict value at next timestep","previous ten days of driver data used as predictor in model, so it is updating iteratively")
#complete_forecasts$Iterative_yn<-complete_forecasts$it_no_update_ic
complete_forecasts$DA_type[complete_forecasts$it_no_update_ic]
complete_forecasts$Automated_bin <- 0
complete_forecasts$Automated_bin[complete_forecasts$Automated_yn %in% c("At least one data stream","Yes all data streams")]<-1
complete_forecasts$Uncert_yn <- 0
complete_forecasts$Uncert_yn <- as.numeric(complete_forecasts$Uncert_category %in% c("data_driven", "propagates", "assimilates"))
sum(complete_forecasts$Uncert_category == "contains")/nrow(complete_forecasts)
sum(complete_forecasts$Uncert_category == "contains")/sum(!complete_forecasts$Uncert_category %in% c("data_driven", "propagates", "assimilates"))

complete_forecasts$Forecast_eval_shown[complete_forecasts$Forecast_eval == 0] <- 0
complete_forecasts%>%
  summarize(aut = sum(Automated_bin)/n(),
            eva = sum(Forecast_eval_shown)/n(),
            unc = sum(Uncert_yn)/n(),
            ite = sum(Iterative_yn)/n(),
            arc = sum(Archiving_yn)/n(),
            use = sum(End_user_yn)/n(),
            dat = sum(Drivers_published)/n(),
            nul = sum(Null_yn)/n(),
            prt = sum(Uncert_partition_yn)/n())

total = complete_forecasts%>%
  group_by(Title)%>%
  summarize(aut = sum(Automated_bin)/n(),
            eva = sum(Forecast_eval_shown)/n(),
            unc = sum(Uncert_yn)/n(),
            ite = sum(Iterative_yn)/n(),
            arc = sum(Archiving_yn)/n(),
            use = sum(End_user_yn)/n(),
            dat = sum(Drivers_published)/n(),
            nul = sum(Null_yn)/n(),
            prt = sum(Uncert_partition_yn)/n(),
            Total = sum(aut,eva,unc,ite,arc,use,dat,nul,prt))
hist(total$Total, breaks = 8)
summary(as.factor(total$Total))
mean(total$Total)
median(total$Total)

complete_forecasts = complete_forecasts%>%
  filter(Year>1932)

aut = glm(Automated_bin~Year, data = complete_forecasts, family = "binomial")
eva = glm(Forecast_eval_shown~Year, data = complete_forecasts, family = "binomial")
unc = glm(Uncert_yn~Year, data = complete_forecasts, family = "binomial")
ite = glm(Iterative_yn~Year, data = complete_forecasts, family = "binomial")
arc = glm(Archiving_yn~Year, data = complete_forecasts, family = "binomial") #p = 0.025
use = glm(End_user_yn~Year, data = complete_forecasts, family = "binomial")
dat = glm(Drivers_published~Year, data = complete_forecasts, family = "binomial") #p < 0.001
nul = glm(Null_yn~Year, data = complete_forecasts, family = "binomial")
prt = glm(Uncert_partition_yn~Year, data = complete_forecasts, family = "binomial")
results = data.frame(var2 = "Include data driven uncertainty")%>%
  full_join(data.frame(summary(unc)$coefficients, var2 = NA)%>% mutate(var = "Include data driven uncertainty"))%>%
  full_join(data.frame(var2 = "Assess and report forecast skill"))%>%
  full_join(data.frame(summary(eva)$coefficients) %>% mutate(var = "Assess and report forecast skill"))%>%
  full_join(data.frame(var2 = "Identify an end user"))%>%
  full_join(data.frame(summary(use)$coefficients) %>% mutate(var = "Identify an end user"))%>%
  full_join(data.frame(var2 = "Make iterative forecasts"))%>%
  full_join(data.frame(summary(ite)$coefficients) %>% mutate(var = "Make iterative forecasts"))%>%
  full_join(data.frame(var2 = "Develop automated forecasting workflows"))%>%
  full_join(data.frame(summary(aut)$coefficients) %>% mutate(var = "Develop automated forecasting workflows"))%>%
  full_join(data.frame(var2 = "Make data available"))%>%
  full_join(data.frame(summary(dat)$coefficients) %>% mutate(var = "Make data available"))%>%
  full_join(data.frame(var2 = "Archive forecasts"))%>%
  full_join(data.frame(summary(arc)$coefficients) %>% mutate(var = "Archive forecasts"))%>%
  full_join(data.frame(var2 = "Use null model comparisons"))%>%
  full_join(data.frame(summary(nul)$coefficients) %>% mutate(var = "Use null model comparisons"))%>%
  full_join(data.frame(var2 = "Partition uncertainty"))%>%
  full_join(data.frame(summary(prt)$coefficients) %>% mutate(var = "Partition uncertainty"))%>%
  mutate(param = rep(c(NA,"Intercept","Year"),9))%>%
  select(var, var2, param, Estimate, Std..Error, z.value, Pr...z..)
results[-c(1,2,3)] = round(results[-c(1,2,3)], 3)
results$param[is.na(results$param)]<-results$var2[is.na(results$param)]
results%>%
  select(-var2, -var)

x = 1980:2020
probs = predict(aut, list(Year = x), type = "response")
prob_df = data.frame(var = rep("Automated_bin",length(x)),x=x,probs=probs)
real_name = c("Automated_bin", "Forecast_eval_shown", "Uncert_yn", "Iterative_yn","Archiving_yn", "End_user_yn","Drivers_published", "Null_yn", "Uncert_partition_yn")
model = c("aut", "eva","unc","ite","arc","use","dat","nul","prt")
for (i in 2:length(model)){
  probs = predict(get(model[i]), list(Year = x), type = "response")
  new = data.frame(var = rep(real_name[i],length(x)),x=x,probs=probs)
  prob_df = prob_df%>%
    full_join(new)
}

cf = complete_forecasts%>%
  select(Automated_bin, Forecast_eval_shown, Uncert_yn, Iterative_yn, Archiving_yn, End_user_yn, Drivers_published, Null_yn, Uncert_partition_yn, Year)%>%
  pivot_longer(cols = -Year)%>%
  rename(var = name, x = Year)
unique(cf$var)

#cf$Tier <- "Baseline"
#cf$Tier[cf$var %in% c("End_user_yn", "Iterative_yn", "Automated_bin")] <- "Decision Support"
#cf$Tier[cf$var %in% c("Drivers_published", "Archiving_yn","Null_yn", "Uncert_partition_yn")] <- "Science"

#prob_df$Tier <- "Baseline"
#prob_df$Tier[prob_df$var %in% c("End_user_yn", "Iterative_yn", "Automated_bin")] <- "Decision Support"
#prob_df$Tier[prob_df$var %in% c("Drivers_published", "Archiving_yn","Null_yn", "Uncert_partition_yn")] <- "Science"

labs = c("Develop automated forecasting workflows","Assess and report forecast skill", "Include data driven uncertainty","Make iterative forecasts","Archive forecasts", "Identify an end user","Make data available", "Use null model comparisons", "Partition uncertainty")
names(labs) = real_name
prob_df$var = factor(prob_df$var, levels = c("Uncert_yn", "Forecast_eval_shown", "End_user_yn", "Iterative_yn", "Automated_bin", "Drivers_published", "Archiving_yn", "Null_yn", "Uncert_partition_yn"))
cf$var = factor(cf$var, levels = c("Uncert_yn", "Forecast_eval_shown", "End_user_yn", "Iterative_yn", "Automated_bin", "Drivers_published", "Archiving_yn", "Null_yn", "Uncert_partition_yn"))
data_frame(var = c("Uncert_yn", "Forecast_eval_shown", "End_user_yn", "Iterative_yn", "Automated_bin", "Drivers_published", "Archiving_yn", "Null_yn", "Uncert_partition_yn"), )
results = results%>%
  filter(param == "Year")%>%
  select(-var2)%>%
  mutate(sig = "")
results$sig[results$Pr...z..<0.05] <- "*"
results$sig[results$Pr...z..<0.01] <- "**"
results$sig[results$Pr...z..<0.001] <- "***"
results$var <- c("Uncert_yn", "Forecast_eval_shown", "End_user_yn", "Iterative_yn", "Automated_bin", "Drivers_published", "Archiving_yn", "Null_yn", "Uncert_partition_yn")
results$var = factor(results$var)

jpeg("../Figures/best_practices_regression.jpg",res = 300,width = 8, height = 6, units = "in")
plot = prob_df%>%
  ggplot(aes(x = x, y = probs))+
  geom_point(aes(y = value), data = cf, alpha = .15, color = "blue")+
  geom_text(aes(x = 2000, y = .85, label = sig), data = results, size = 6)+
  geom_line()+
  ylim(0,1)+
  facet_wrap(~var, labeller = labeller(var = labs))+
  theme_bw()+
  ylab("Probability")+
  xlab("Year")
plot
dev.off()
plot
```


Time-series data
```{r}
complete_forecasts <- read.csv("../Data/complete_dataset_with_source.csv")
mean_dc<- round(mean(as.numeric(complete_forecasts$Data_coverage)/365, na.rm = T),1)
min(as.numeric(complete_forecasts$Data_coverage), na.rm = T)
max(as.numeric(complete_forecasts$Data_coverage)/365, na.rm = T)
median_dc <- round(median(as.numeric(complete_forecasts$Data_coverage)/365, na.rm = T),1)
lines = data.frame(c(mean_dc, median_dc),c(2,2))
colnames(lines) = c("x","y")
lines$label = c(paste0("Mean = ", mean_dc, " years"), paste0("Median = ",median_dc, " years"))

jpeg("../Figures/Years_of_data.jpeg", res = 300, width = 8, height = 4, units = "in")
complete_forecasts%>%
  mutate(Year = as.numeric(Year))%>%
  ggplot()+
  geom_histogram(aes(x = as.numeric(Data_coverage)/365),bins = 10)+
  geom_vline(xintercept = c(mean_dc, median_dc), color = "white")+
  geom_text(aes(x = x,y=y,label= label), data = lines, angle = 90, nudge_x = -2, hjust = 0,color = "white")+
  xlab("Years of data used to create forecasting paper")+
  ylab("Number of papers")+
  theme_light()
dev.off()

### Statistics
sum(as.numeric(complete_forecasts$Data_coverage)>(10*365), na.rm = T)/nrow(complete_forecasts)
complete_forecasts[as.numeric(complete_forecasts$Data_coverage)>100*365,]
```

```{r}
complete_forecasts <- read.csv("../Data/complete_dataset_with_source.csv")
time_bin = complete_forecasts
time_bin$time_bin = NA
time_bin$Time_step_days[is.na(as.numeric(time_bin$Time_step_days))] ##Use this line to check if you have all of the complicated cases covered
time_bin$time_bin[time_bin$Time_step_days == "30-150"] <- "> 1 - 12 months"
time_bin$time_bin[time_bin$Time_step_days == "1,7,15,30"] <- "1 - 30 days"
time_bin = time_bin %>%
    mutate(Time_step_days = as.numeric(Time_step_days))

time_bin$time_bin[time_bin$Time_step_days < 1] <- "< 1 day"
time_bin$time_bin[time_bin$Time_step_days == 1] <- "1 day"
time_bin$time_bin[time_bin$Time_step_days > 1 & time_bin$Time_step_days <= 7] <- "2 - 7 days"
time_bin$time_bin[time_bin$Time_step_days > 7 & time_bin$Time_step_days <= 31] <- "8 days - 1 month"
time_bin$time_bin[time_bin$Time_step_days > 31 & time_bin$Time_step_days < 365] <- "> 1 month - 1 year"
time_bin$time_bin[time_bin$Time_step_days == 365] <- "1 year"
time_bin$time_bin[time_bin$Time_step_days > 365 & time_bin$Time_step_days >= 365*5] <- "> 1 year - 5 years"
time_bin$time_bin[time_bin$Time_step_days > 365*5] <- "> 5 years"


time_bin$time_bin <- factor(time_bin$time_bin, levels = c("< 1 day", "1 day","2 - 7 days","8 days - 1 month","> 1 month - 1 year","1 year","> 1 year - 5 years", "> 5 years"))

time_bin$horiz_bin = NA
time_bin$Horiz_days[is.na(as.numeric(time_bin$Horiz_days))]
time_bin$horiz_bin[time_bin$Horiz_days == "30-150"] <- "> 1 month - 1 year"
time_bin$horiz_bin[time_bin$Horiz_days == "720 - 1800 (sites had different amounts of data)"] <- "> 1 year - 5 years"
time_bin$horiz_bin[time_bin$Horiz_days == "365 and 3650"] <- "> 5 years - 10 years"
time_bin$horiz_bin[time_bin$Horiz_days == "7, 3650"] <- "2 - 7 days" #Because timestep is listed as 1 day 
time_bin$horiz_bin[time_bin$Horiz_days == "14-77"] <- "> 1 month - 1 year"

time_bin = time_bin %>%
    mutate(Horiz_days = as.numeric(Horiz_days))
time_bin$horiz_bin[time_bin$Horiz_days < 1] <- "< 1 day"
time_bin$horiz_bin[time_bin$Horiz_days == 1] <- "1 day"
time_bin$horiz_bin[time_bin$Horiz_days > 1 & time_bin$Horiz_days <= 7] <- "2 - 7 days"
time_bin$horiz_bin[time_bin$Horiz_days > 7 & time_bin$Horiz_days <= 31] <- "8 days - 1 month"
time_bin$horiz_bin[time_bin$Horiz_days > 31 & time_bin$Horiz_days < 365] <- "> 1 month - 1 year"
time_bin$horiz_bin[time_bin$Horiz_days == 365] <- "1 year"
time_bin$horiz_bin[time_bin$Horiz_days > 365 & time_bin$Horiz_days <= 365*5] <- "> 1 year - 5 years"
time_bin$horiz_bin[time_bin$Horiz_days > 365*5] <- "> 5 years"
time_bin$horiz_bin <- factor(time_bin$horiz_bin, levels = c("< 1 day", "1 day","2 - 7 days","8 days - 1 month","> 1 month - 1 year","1 year","> 1 year - 5 years", "> 5 years"))

time_bin$time_bin <- factor(time_bin$time_bin, levels = c("< 1 day", "1 day","2 - 7 days","8 days - 1 month","> 1 month - 1 year","1 year","> 1 year - 5 years"))

time_bin_plot = time_bin%>%
  filter(!is.na(horiz_bin),
         !is.na(time_bin))

times = c("< 1 day", "1 day","2 - 7 days","8 days - 1 month","> 1 month - 1 year","1 year","> 1 year - 5 years")
horiz = c("< 1 day", "1 day","2 - 7 days","8 days - 1 month","> 1 month - 1 year","1 year","> 1 year - 5 years", "> 5 years")
fix = data.frame(horiz_bin = rep(times, length(horiz)), time_bin = rep(horiz, each = length(times)))

n = time_bin_plot%>%
  group_by(horiz_bin,time_bin)%>%
  summarise(ns = n())%>%
  mutate(color = ns>20)

jpeg("../Figures/timestep_heatmap.jpeg",res = 300,width = 7, height = 4, units = "in")
library("RColorBrewer")
cols <- brewer.pal(n = 9, name = "BuPu")
time_bin_plot%>%
  ggplot(aes(x = horiz_bin, y = time_bin), na.rm = T)+
  geom_bin2d()+
  xlab("Time horizon")+
  ylab("Time step")+
  scale_fill_gradientn(colors = cols)+
  scale_x_discrete(drop  =F)+
  scale_y_discrete(drop  =F)+
  geom_text(aes(label = ns, color = color), data = n, show.legend = F)+ #Can get rid of this by commenting out
  theme_light()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank())+
  scale_color_manual(values = c("gray40","gray90"))
dev.off()
time_bin$horiz_bin
nrow(time_bin%>%filter(horiz_bin %in% c("< 1 day", "1 day","2 - 7 days","8 days - 1 month","> 1 month - 1 year","1 year")))/nrow(time_bin%>%filter(!is.na(horiz_bin)))*100
nrow(time_bin%>%filter(horiz_bin %in% c("2 - 7 days"),time_bin %in% c("1 day")))/nrow(time_bin%>%filter(!is.na(horiz_bin)))*100
nrow(time_bin%>%filter(horiz_bin %in% c("1 year"),time_bin %in% c("1 year")))/nrow(time_bin%>%filter(!is.na(horiz_bin)))*100
```