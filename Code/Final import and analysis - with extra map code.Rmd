---
title: "Final data ingest and analysis"
author: "Abby Lewis"
date: "10/29/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(colorspace)
```

Papers per year
```{r}
complete_forecasts <- read.csv("../Data/complete_dataset_with_source.csv") #Load data
sum(complete_forecasts$Ethical_considerations ==1, na.rm = T)/nrow(complete_forecasts)
sum(complete_forecasts$End_user_yn==1&complete_forecasts$Used_by_stakeholder_yn==1, na.rm = T)/sum(complete_forecasts$End_user_yn==1,na.rm = T)
sum(complete_forecasts$End_user_yn==1&complete_forecasts$End_user_partnership==1, na.rm = T)/sum(complete_forecasts$End_user_yn==1,na.rm = T)
sum(complete_forecasts$End_user_yn==1&complete_forecasts$Used_by_stakeholder_yn==1&complete_forecasts$Ethical_considerations==1, na.rm = T)/sum(complete_forecasts$End_user_yn==1&complete_forecasts$Used_by_stakeholder_yn==1, na.rm = T)
sum(complete_forecasts$End_user_yn==1&complete_forecasts$Used_by_stakeholder_yn==1&complete_forecasts$Ethical_considerations==1, na.rm = T)/sum(complete_forecasts$End_user_yn==1&complete_forecasts$Used_by_stakeholder_yn==1, na.rm = T)

#Plot the number of papers published per year
jpeg("../Figures/Pubs_year_noEco.jpeg", width = 3, height = 3, units = "in",res = 600)
complete_forecasts%>%
  ggplot()+
  geom_histogram(aes(x = Year),binwidth = 1)+
  theme_bw()+
  xlab("Year")+
  ylab("Near-term ecological forecasts")+
  ylim(0,25)+
  scale_x_continuous(limits = c(1930,2020), expand = c(0,0))+
  theme(text=element_text(size=10,  family="Helvetica"))
dev.off()
```

Uncertainty type statistics
```{r}
complete_forecasts[complete_forecasts$Forecast_eval== "1",]
complete_forecasts$Uncert_source[complete_forecasts$Uncert_category == "no"] <- NA
complete_forecasts$Driver <- grepl("driver|meteo", complete_forecasts$Uncert_source, ignore.case = T)*1
complete_forecasts$Process <- grepl("process", complete_forecasts$Uncert_source, ignore.case = T)*1
complete_forecasts$Param <- grepl("param", complete_forecasts$Uncert_source, ignore.case = T)*1
complete_forecasts$IC <- grepl("init|ic", complete_forecasts$Uncert_source, ignore.case = T)*1
complete_forecasts$Obs <- grepl("obs", complete_forecasts$Uncert_source, ignore.case = T)*1

complete_forecasts%>%
  filter(!Uncert_category=="no")%>%
  summarize(driv = sum(Driver)/n(),
            proc = sum(Process)/n(),
            param = sum(Param)/n(),
            ic = sum(IC)/n(),
            obs = sum(Obs)/n())
```

Most common variables (statistics for paper)
```{r}
complete_forecasts$Vars_ident[grepl("ET |evap",complete_forecasts$Vars_ident,ignore.case = T)]
complete_forecasts$Vars_ident[grepl("pollen",complete_forecasts$Vars_ident,ignore.case = T)]
complete_forecasts$Vars_ident[grepl("diatom|cyano|oscillatoria|asterionella|desmus|anab|aphaniz|synecho|cyclo|stephanodiscus|raciborskii|circinale",complete_forecasts$Vars_ident, ignore.case = T)]
complete_forecasts$Vars_ident[grepl("chl",complete_forecasts$Vars_ident, ignore.case = T)]
complete_forecasts$Vars_ident[grepl("alg|hab |phyto",complete_forecasts$Vars_ident, ignore.case = T)]
complete_forecasts$Vars_ident[!grepl("yield",complete_forecasts$Vars_ident, ignore.case = T)]
complete_forecasts$Vars_ident[grepl("catch|fish|pollock|salmon|anchovy|walleye|herring|trout|carp",complete_forecasts$Vars_ident, ignore.case = T)] #except not lobster catch, shellfish harvesting, rusty crayfish distribution
```

Journals and languages represented
```{r}
length(unique(journals$Source)) #114 different journals
```

Map
```{r}
complete_forecasts <- read.csv("../Data/complete_dataset_with_source.csv")
WorldData <- map_data('world') %>% 
  fortify()
safe_colorblind_palette <- c("#661100", "#AA4499", "#DDCC77", "#117733","#44AA99","#999933","#332288", "#88CCEE", "#CC6677","#888888")


for_map <- complete_forecasts
coords <- for_map$Coords
for(i in 1:(max(str_count(for_map$Coords, ";"), na.rm = T)+1)){
  stops <- regexpr(pattern = ";",coords)
  stops[stops == -1] <- 10000L
  coords_i <- substr(coords, start = 1, stop = stops-1)
  for_map[nchar(coords_i)>0&!is.na(coords_i), paste0("Long",i)] <- as.numeric(sub("-*[0-9]+.[0-9]+,","",coords_i))[nchar(coords_i)>0&!is.na(coords_i)]
  for_map[nchar(coords_i)>0&!is.na(coords_i), paste0("Lat",i)] <- as.numeric(sub(", -*[0-9]+.[0-9]+","",coords_i))[nchar(coords_i)>0&!is.na(coords_i)]
  inds <- regexpr(pattern = ";",coords)
  inds[inds == -1]<-NA
  coords <- substr(coords, start = inds + 2, stop = 10000L)
}

for_map2 = for_map%>%
  pivot_longer(cols = num_range("Lat", 1:max(str_count(for_map$Coords, ";")+1, na.rm = T)), names_to = "Lat_num", values_to= "Lat")%>%
  pivot_longer(cols = num_range("Long", 1:max(str_count(for_map$Coords, ";")+1, na.rm = T)), names_to = "Long_num", values_to = "Long")%>%
  filter(sub("[a-z]+","",Lat_num)==sub("[a-z]+","",Long_num, ""))%>%
  filter(!Spat_scale == "global")

colors = lighten(safe_colorblind_palette, amount = .2)

for_map2$Region <- NA
for_map2$Region[for_map2$Spat_scale %in% c("regional","national")] <- 1
for_map2$Region[for_map2$Spat_scale %in% c("point","multipoint")]<-0

map <- ggplot() +
  geom_map(data = WorldData, map = WorldData,
                  aes(map_id=region),
                  fill = "white", colour = "#7f7f7f", size=0.5)+
  coord_map("rectangular", lat0=0, xlim=c(-180,180), ylim = c(-90,90))+
  geom_point(data = for_map2%>%filter(Region == 1), aes(Long, Lat, fill = Ecosystem), shape = 21, color = "white", size = 6, alpha  =.3, stroke = .5, show.legend = F)+
  geom_point(data = for_map2%>%filter(Region == 0), aes(Long, Lat, fill = Ecosystem), shape = 21, color = "white", size = 2.5, alpha  =1, stroke = .5, show.legend = F)+
  geom_point(aes(x = c(-300,-300), y=c(-300,-300),size = c("point or multipoint","regional or national"), alpha = c("point or multipoint","regional or national")), shape = 21, color = "white",fill = "grey20")+
  xlab(NULL) + ylab(NULL) +
  scale_fill_manual(breaks = c("agricultural", "atmosphere", "desert", "forest", "freshwater", "grassland", "marine", "tundra", "urban", "other", "NA"), values = colors, na.translate = T, na.value = "grey50", name = "Ecosystem")+
  theme_void()+
  theme(legend.title = element_blank(), 
    legend.position = c(.15,.4),
    text=element_text(size=10,  family="Helvetica"),
    plot.margin = margin(0, 0, 0, 0, "cm"),
    legend.box.background = element_rect(fill = "white", color = "white"))+
  guides(size = guide_legend(override.aes = list(size = c(3,6))),alpha = guide_legend(override.aes = list(alpha = c(1,.3))))

library(broom)
us <- ggplot() +
  geom_map(data = WorldData, map = WorldData,
                  aes(map_id=region),
                  fill = "white", colour = "#7f7f7f", size=0.5)+
  coord_quickmap(xlim=c(-128,-68), ylim = c(17,57), expand = F, clip = "on")+
  geom_point(data = for_map2%>%filter(Region == 1), aes(Long, Lat, fill = Ecosystem), shape = 21, color = "white", size = 6, alpha  =.3, stroke = .5, show.legend = F)+
  geom_point(data = for_map2%>%filter(Region == 0), aes(Long, Lat, fill = Ecosystem), shape = 21, color = "white", size = 3, alpha  =1, stroke = .5, show.legend = F)+ 
  xlab(NULL) + 
  ylab(NULL) +
  scale_fill_manual(breaks = c("agricultural", "atmosphere", "desert", "forest", "freshwater", "grassland", "marine", "tundra", "urban", "other", "NA"), values = colors, na.translate = T, na.value = "grey50", name = "Ecosystem")+
  theme_void()+
  theme(text=element_text(size=10,  family="Helvetica"))+
  ggtitle("United States")
us

eur <- ggplot() +
  geom_map(data = WorldData, map = WorldData,
                  aes(map_id=region),
                  fill = "white", colour = "#7f7f7f", size=0.5)+
  coord_quickmap(xlim = c(-15,45), ylim = c(30,70),expand = F, clip = "on")+
  geom_point(data = for_map2%>%filter(Region == 1), aes(Long, Lat, fill = Ecosystem), shape = 21, color = "white", size = 6, alpha  =.3, stroke = .5, show.legend = F)+
  geom_point(data = for_map2%>%filter(Region == 0), aes(Long, Lat, fill = Ecosystem), shape = 21, color = "white", size = 3, alpha  =1, stroke = .5, show.legend = F)+ 
  xlab(NULL) + 
  ylab(NULL) +
  scale_fill_manual(breaks = c("agricultural", "atmosphere", "desert", "forest", "freshwater", "grassland", "marine", "tundra", "urban", "other", "NA"), values = colors, na.translate = T, na.value = "grey50", name = "Ecosystem")+
  theme_void()+
  theme(text=element_text(size=10,  family="Helvetica"))+
  ggtitle("Europe")
eur

chi <- ggplot() +
  geom_map(data = WorldData, map = WorldData,
                  aes(map_id=region),
                  fill = "white", colour = "#7f7f7f", size=0.5)+
  coord_quickmap(xlim = c(90,150),ylim = c(17,57), expand = F, clip = "on")+
  geom_point(data = for_map2%>%filter(Region == 1), aes(Long, Lat, fill = Ecosystem), shape = 21, color = "white", size = 6, alpha  =.3, stroke = .5, show.legend = F)+
  geom_point(data = for_map2%>%filter(Region == 0), aes(Long, Lat, fill = Ecosystem), shape = 21, color = "white", size = 3, alpha  =1, stroke = .5, show.legend = F)+ 
  xlab(NULL) + 
  ylab(NULL) +
  scale_fill_manual(breaks = c("agricultural", "atmosphere", "desert", "forest", "freshwater", "grassland", "marine", "tundra", "urban", "other", "NA"), values = colors, na.translate = T, na.value = "grey50", name = "Ecosystem")+
  theme_void()+
  theme(text=element_text(size=10,  family="Helvetica"))+
  ggtitle("China")
chi


complete_forecasts$Ecosystem[is.na(complete_forecasts$Ecosystem)]<-"NA"
complete_forecasts$Ecosystem <- factor(complete_forecasts$Ecosystem, levels = c("agricultural","desert","grassland","forest","atmosphere","freshwater","marine","tundra","urban","other","NA"))
complete_forecasts$Spat_scale<- factor(complete_forecasts$Spat_scale, levels = c("point","multipoint","regional","national","global"))
extent <- complete_forecasts%>%
  ggplot(aes(x = Spat_scale, fill = Ecosystem))+
  scale_fill_manual(breaks = c("agricultural", "atmosphere", "desert", "forest", "freshwater", "grassland", "marine", "tundra", "urban", "other", "NA"), values = colors, na.translate = T, na.value = "grey50", name = "Ecosystem")+
  xlab("Spatial extent")+
  geom_bar(show.legend = F)+
  ylab("Papers (n)")+
  theme_light()+
  theme(text=element_text(size=10,  family="Helvetica"))

class <- complete_forecasts%>%
  ggplot(aes(x = Class, fill = Ecosystem))+
  geom_bar()+
  scale_fill_manual(breaks = c("agricultural", "atmosphere", "desert", "forest", "freshwater", "grassland", "marine", "tundra", "urban", "other", "NA"), values = colors, na.translate = T, na.value = "grey50", name = "Ecosystem",guide = guide_legend(position = "bottom", nrow = 2))+
  theme(text=element_text(size=10,  family="Helvetica"))

class_long <- complete_forecasts%>%
  ggplot(aes(x = Class, fill = Ecosystem))+
  geom_bar()+
  scale_fill_manual(breaks = c("agricultural", "atmosphere", "desert", "forest", "freshwater", "grassland", "marine", "tundra", "urban", "other", "NA"), values = colors, na.translate = T, na.value = "grey50", name = "Ecosystem",guide = guide_legend(position = "bottom", nrow = 5))+
  theme(text=element_text(size=10,  family="Helvetica"))

g_legend<-function(a.gplot){
  tmp <- ggplot_gtable(ggplot_build(a.gplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)}

legend_fill <- g_legend(class)

legend_long <- g_legend(class_long)

class <- complete_forecasts%>%
  ggplot(aes(x = Class, fill = Ecosystem))+
  geom_bar(show.legend = F)+
  scale_fill_manual(breaks = c("agricultural", "atmosphere", "desert", "forest", "freshwater", "grassland", "marine", "tundra", "urban", "other", "NA"), values = colors, na.translate = T, na.value = "grey50", name = "Ecosystem")+
  ylab("Papers (n)")+
  theme_light()+
  theme(text=element_text(size=10,  family="Helvetica"))

library(ggpubr)
jpeg("../Figures/Map_composite.jpeg",width = 6, height = 5.5, units = "in", res = 600)
ggarrange(map, ggarrange(extent, class, labels = c("B","C"), label.y = c(1.2,1.2), nrow = 1, widths = c(1.4,1)), legend_fill, nrow = 3, heights = c(6.2,3,1.5), labels = "A", align = "h")
dev.off()

jpeg("../Figures/Map_composite_insets.jpeg",width = 6, height = 8, units = "in", res = 600)
ggarrange(map, ggarrange(us, eur, nrow = 1, widths = c(1,1)), ggarrange(chi, legend_long, widths = c(1,1), nrow = 1),nrow = 3, heights = c(1,.8,.8))
dev.off()

jpeg("../Figures/Map_composite_EVERYTHING.jpeg",width = 6, height = 8, units = "in", res = 600)
ggarrange(map, ggarrange(us, eur, nrow = 1, widths = c(1,1)), ggarrange(chi, legend_long, widths = c(1,1), nrow = 1), ggarrange(extent, class, labels = c("B","C"), label.y = c(1.2,1.2), nrow = 1, widths = c(1.4,1)), nrow = 4, heights = c(1,.8,.8,.8))
#, nrow = 4, heights = c(2,3,3,2), widths = c(10,1,1,1),labels = "A", align = "h")
dev.off()

jpeg("../Figures/Class_extent.jpeg",width = 3, height = 5, units = "in", res = 600)
ggarrange(ggarrange(extent, class, labels = c("A","B"), label.y = c(1,1), nrow = 2), legend_fill, nrow = 2, heights = c(2,.7))
dev.off()

### Summary statistics
north_analysis <- for_map2$Lat[!is.na(for_map2$Lat)]
sum(north_analysis>0)/length(north_analysis)
sum(complete_forecasts$Spat_scale=="regional")/nrow(complete_forecasts)
sum(complete_forecasts$Class=="organismal"|complete_forecasts$Class=="both")/nrow(complete_forecasts)
sum(complete_forecasts$Ecosystem=="agricultural")/nrow(complete_forecasts)
```

Logistic regression
```{r}
complete_forecasts <- read.csv("../Data/complete_dataset_with_source.csv")
complete_forecasts$it_no_update_ic <- complete_forecasts$Iterative_yn==1&!complete_forecasts$DA_type%in%c("update IC","autoregressive, so new observed data become predictors for the next timestep","UNK","NA","autoregressive, uses previous observations to predict value at next timestep","previous ten days of driver data used as predictor in model, so it is updating iteratively")
#complete_forecasts$Iterative_yn<-complete_forecasts$it_no_update_ic
complete_forecasts$Automated_bin <- 0
complete_forecasts$Automated_bin[complete_forecasts$Automated_yn %in% c("At least one data stream","Yes all data streams")]<-1
complete_forecasts$Uncert_yn <- as.numeric(!complete_forecasts$Uncert_category == "no")

#complete_forecasts$Uncert_yn <- as.numeric(complete_forecasts$Uncert_category %in% c("data_driven", "propagates", "assimilates"))
sum(complete_forecasts$Uncert_category == "contains")/sum(complete_forecasts$Uncert_yn)
sum(complete_forecasts$Uncert_yn)/nrow(complete_forecasts)

sum(as.numeric(complete_forecasts$Uncert_obs_yn==1))/sum(complete_forecasts$Uncert_yn)

complete_forecasts$Forecast_eval_shown[complete_forecasts$Forecast_eval == 0] <- 0
complete_forecasts%>%
  summarize(aut = sum(Automated_bin)/n(),
            aut_n = sum(Automated_bin),
            eva = sum(Forecast_eval_shown)/n(),
            eva_n = sum(Forecast_eval_shown),
            unc = sum(Uncert_yn)/n(),
            unc_n = sum(Uncert_yn),
            ite = sum(Iterative_yn)/n(),
            ite_n = sum(Iterative_yn),
            arc = sum(Archiving_yn)/n(),
            arc_n = sum(Archiving_yn),
            use = sum(End_user_yn)/n(),
            use_n = sum(End_user_yn),
            dat = sum(Drivers_published)/n(),
            dat_n = sum(Drivers_published),
            nul = sum(Null_yn)/n(),
            nul_n = sum(Null_yn),
            prt = sum(Uncert_partition_yn)/n(),
            prt_n = sum(Uncert_partition_yn))

total = complete_forecasts%>%
  group_by(Title)%>%
  summarize(aut = sum(Automated_bin)/n(),
            eva = sum(Forecast_eval_shown)/n(),
            unc = sum(Uncert_yn)/n(),
            ite = sum(Iterative_yn)/n(),
            arc = sum(Archiving_yn)/n(),
            use = sum(End_user_yn)/n(),
            dat = sum(Drivers_published)/n(),
            nul = sum(Null_yn)/n(),
            prt = sum(Uncert_partition_yn)/n(),
            Total = sum(aut,eva,unc,ite,arc,use,dat,nul,prt))
summary(as.factor(total$Total))
mean(total$Total)
median(total$Total)

complete_forecasts = complete_forecasts%>%
  filter(Year>1932)

aut = glm(Automated_bin~Year, data = complete_forecasts, family = "binomial")
eva = glm(Forecast_eval_shown~Year, data = complete_forecasts, family = "binomial")
unc = glm(Uncert_yn~Year, data = complete_forecasts, family = "binomial")
ite = glm(Iterative_yn~Year, data = complete_forecasts, family = "binomial")
arc = glm(Archiving_yn~Year, data = complete_forecasts, family = "binomial") #p = 0.025
use = glm(End_user_yn~Year, data = complete_forecasts, family = "binomial")
dat = glm(Drivers_published~Year, data = complete_forecasts, family = "binomial") #p < 0.001
nul = glm(Null_yn~Year, data = complete_forecasts, family = "binomial")
prt = glm(Uncert_partition_yn~Year, data = complete_forecasts, family = "binomial")
results = data.frame(var2 = "Include data driven uncertainty")%>%
  full_join(data.frame(summary(unc)$coefficients, var2 = NA)%>% mutate(var = "Include data driven uncertainty"))%>%
  full_join(data.frame(var2 = "Assess and report forecast skill"))%>%
  full_join(data.frame(summary(eva)$coefficients) %>% mutate(var = "Assess and report forecast skill"))%>%
  full_join(data.frame(var2 = "Identify an end user"))%>%
  full_join(data.frame(summary(use)$coefficients) %>% mutate(var = "Identify an end user"))%>%
  full_join(data.frame(var2 = "Make iterative forecasts"))%>%
  full_join(data.frame(summary(ite)$coefficients) %>% mutate(var = "Make iterative forecasts"))%>%
  full_join(data.frame(var2 = "Develop automated forecasting workflows"))%>%
  full_join(data.frame(summary(aut)$coefficients) %>% mutate(var = "Develop automated forecasting workflows"))%>%
  full_join(data.frame(var2 = "Make data available"))%>%
  full_join(data.frame(summary(dat)$coefficients) %>% mutate(var = "Make data available"))%>%
  full_join(data.frame(var2 = "Archive forecasts"))%>%
  full_join(data.frame(summary(arc)$coefficients) %>% mutate(var = "Archive forecasts"))%>%
  full_join(data.frame(var2 = "Use null model comparisons"))%>%
  full_join(data.frame(summary(nul)$coefficients) %>% mutate(var = "Use null model comparisons"))%>%
  full_join(data.frame(var2 = "Partition uncertainty"))%>%
  full_join(data.frame(summary(prt)$coefficients) %>% mutate(var = "Partition uncertainty"))%>%
  mutate(param = rep(c(NA,"Intercept","Year"),9))%>%
  select(var, var2, param, Estimate, Std..Error, z.value, Pr...z..)
results[-c(1,2,3)] = round(results[-c(1,2,3)], 3)
results$param[is.na(results$param)]<-results$var2[is.na(results$param)]
results%>%
  select(-var2, -var)

x = 1980:2020
probs = predict(aut, list(Year = x), type = "response")
prob_df = data.frame(var = rep("Automated_bin",length(x)),x=x,probs=probs)
real_name = c("Automated_bin", "Forecast_eval_shown", "Uncert_yn", "Iterative_yn","Archiving_yn", "End_user_yn","Drivers_published", "Null_yn", "Uncert_partition_yn")
model = c("aut", "eva","unc","ite","arc","use","dat","nul","prt")
for (i in 2:length(model)){
  probs = predict(get(model[i]), list(Year = x), type = "response")
  new = data.frame(var = rep(real_name[i],length(x)),x=x,probs=probs)
  prob_df = prob_df%>%
    full_join(new)
}

cf = complete_forecasts%>%
  select(Automated_bin, Forecast_eval_shown, Uncert_yn, Iterative_yn, Archiving_yn, End_user_yn, Drivers_published, Null_yn, Uncert_partition_yn, Year)%>%
  pivot_longer(cols = -Year)%>%
  rename(var = name, x = Year)
unique(cf$var)

#cf$Tier <- "Baseline"
#cf$Tier[cf$var %in% c("End_user_yn", "Iterative_yn", "Automated_bin")] <- "Decision Support"
#cf$Tier[cf$var %in% c("Drivers_published", "Archiving_yn","Null_yn", "Uncert_partition_yn")] <- "Science"

#prob_df$Tier <- "Baseline"
#prob_df$Tier[prob_df$var %in% c("End_user_yn", "Iterative_yn", "Automated_bin")] <- "Decision Support"
#prob_df$Tier[prob_df$var %in% c("Drivers_published", "Archiving_yn","Null_yn", "Uncert_partition_yn")] <- "Science"

labs = c("Automate forecasting workflows","Assess and report forecast skill", "Include uncertainty","Make iterative forecasts","Archive forecasts", "Identify an end user","Make data available", "Use null model comparisons", "Partition uncertainty")
names(labs) = real_name
prob_df$var = factor(prob_df$var, levels = c("Uncert_yn", "Forecast_eval_shown", "End_user_yn", "Iterative_yn", "Automated_bin", "Drivers_published", "Archiving_yn", "Null_yn", "Uncert_partition_yn"))
cf$var = factor(cf$var, levels = c("Uncert_yn", "Forecast_eval_shown", "End_user_yn", "Iterative_yn", "Automated_bin", "Drivers_published", "Archiving_yn", "Null_yn", "Uncert_partition_yn"))
data_frame(var = c("Uncert_yn", "Forecast_eval_shown", "End_user_yn", "Iterative_yn", "Automated_bin", "Drivers_published", "Archiving_yn", "Null_yn", "Uncert_partition_yn"), )
results = results%>%
  filter(param == "Year")%>%
  select(-var2)%>%
  mutate(sig = "")
results$sig[results$Pr...z..<0.05] <- "*"
results$sig[results$Pr...z..<0.01] <- "**"
results$sig[results$Pr...z..<0.001] <- "***"
results$var <- c("Uncert_yn", "Forecast_eval_shown", "End_user_yn", "Iterative_yn", "Automated_bin", "Drivers_published", "Archiving_yn", "Null_yn", "Uncert_partition_yn")
results$var = factor(results$var)

jpeg("../Figures/best_practices_regression.jpg",res = 600,width = 6, height = 5, units = "in")
plot = prob_df%>%
  ggplot(aes(x = x, y = probs))+
  geom_point(aes(y = value), data = cf, alpha = .15, color = "blue")+
  geom_text(aes(x = 2000, y = .85, label = sig), data = results, size = 6)+
  geom_line()+
  ylim(0,1)+
  facet_wrap(~var, labeller = labeller(var = labs))+
  theme_bw()+
  ylab("Probability")+
  xlab("Year")+
  theme(text=element_text(size=10,  family="Helvetica"))
plot
dev.off()
```


Time-series data
```{r}
complete_forecasts <- read.csv("../Data/complete_dataset_with_source.csv")
mean_dc<- round(mean(as.numeric(complete_forecasts$Data_coverage)/365, na.rm = T),1)
min(as.numeric(complete_forecasts$Data_coverage), na.rm = T)
max(as.numeric(complete_forecasts$Data_coverage)/365, na.rm = T)
median_dc <- round(median(as.numeric(complete_forecasts$Data_coverage)/365, na.rm = T),1)
lines = data.frame(c(mean_dc),c(38))
colnames(lines) = c("x","y")
lines$label = c(paste0("Median = ",median_dc, " years \nMean = ", mean_dc, " years"))

jpeg("../Figures/Years_of_data.jpeg", res = 600, width = 3, height = 3, units = "in")
complete_forecasts%>%
  mutate(Year = as.numeric(Year))%>%
  ggplot()+
  geom_histogram(aes(x = as.numeric(Data_coverage)/365),bins = 20)+
  geom_vline(xintercept = c(mean_dc, median_dc), color = "black")+
  geom_text(aes(x = x,y=y,label= label), data = lines, nudge_x = 3, hjust = 0,vjust = 0,color = "grey20", size = 2.9)+
  xlab("Years of data used to \ncreate forecasting paper")+
  ylab("Number of papers")+
  scale_y_continuous(limits = c(0,46), expand = c(0, 0))+
  theme_light()+
  theme(text=element_text(size=10,  family="Helvetica"))
dev.off()

### Statistics
sum(as.numeric(complete_forecasts$Data_coverage)>(10*365), na.rm = T)/nrow(complete_forecasts)
complete_forecasts[as.numeric(complete_forecasts$Data_coverage)>100*365,]
```

```{r}
complete_forecasts <- read.csv("../Data/complete_dataset_with_source.csv")
time_bin = complete_forecasts
time_bin$time_bin = NA
time_bin$Time_step_days[is.na(as.numeric(time_bin$Time_step_days))] ##Use this line to check if you have all of the complicated cases covered
time_bin$time_bin[time_bin$Time_step_days == "30-150"] <- "> 1 - 12 months"
time_bin$time_bin[time_bin$Time_step_days == "1,7,15,30"] <- "1 - 30 days"
time_bin = time_bin %>%
    mutate(Time_step_days = as.numeric(Time_step_days))

time_bin$time_bin[time_bin$Time_step_days < 1] <- "< 1 day"
time_bin$time_bin[time_bin$Time_step_days == 1] <- "1 day"
time_bin$time_bin[time_bin$Time_step_days > 1 & time_bin$Time_step_days <= 7] <- "2 - 7 days"
time_bin$time_bin[time_bin$Time_step_days > 7 & time_bin$Time_step_days <= 31] <- "8 days - 1 month"
time_bin$time_bin[time_bin$Time_step_days > 31 & time_bin$Time_step_days < 365] <- "> 1 month - 1 year"
time_bin$time_bin[time_bin$Time_step_days == 365] <- "1 year"
time_bin$time_bin[time_bin$Time_step_days > 365 & time_bin$Time_step_days >= 365*5] <- "> 1 year - 5 years"
time_bin$time_bin[time_bin$Time_step_days > 365*5] <- "> 5 years"


time_bin$time_bin <- factor(time_bin$time_bin, levels = c("< 1 day", "1 day","2 - 7 days","8 days - 1 month","> 1 month - 1 year","1 year","> 1 year - 5 years", "> 5 years"))

time_bin$horiz_bin = NA
time_bin$Horiz_days[is.na(as.numeric(time_bin$Horiz_days))]
time_bin$horiz_bin[time_bin$Horiz_days == "30-150"] <- "> 1 month - 1 year"
time_bin$horiz_bin[time_bin$Horiz_days == "720 - 1800 (sites had different amounts of data)"] <- "> 1 year - 5 years"
time_bin$horiz_bin[time_bin$Horiz_days == "365 and 3650"] <- "> 5 years - 10 years"
time_bin$horiz_bin[time_bin$Horiz_days == "7, 3650"] <- "2 - 7 days" #Because timestep is listed as 1 day 
time_bin$horiz_bin[time_bin$Horiz_days == "14-77"] <- "> 1 month - 1 year"

time_bin = time_bin %>%
    mutate(Horiz_days = as.numeric(Horiz_days))
time_bin$horiz_bin[time_bin$Horiz_days < 1] <- "< 1 day"
time_bin$horiz_bin[time_bin$Horiz_days == 1] <- "1 day"
time_bin$horiz_bin[time_bin$Horiz_days > 1 & time_bin$Horiz_days <= 7] <- "2 - 7 days"
time_bin$horiz_bin[time_bin$Horiz_days > 7 & time_bin$Horiz_days <= 31] <- "8 days - 1 month"
time_bin$horiz_bin[time_bin$Horiz_days > 31 & time_bin$Horiz_days < 365] <- "> 1 month - 1 year"
time_bin$horiz_bin[time_bin$Horiz_days == 365] <- "1 year"
time_bin$horiz_bin[time_bin$Horiz_days > 365 & time_bin$Horiz_days <= 365*5] <- "> 1 year - 5 years"
time_bin$horiz_bin[time_bin$Horiz_days > 365*5] <- "> 5 years"
time_bin$horiz_bin <- factor(time_bin$horiz_bin, levels = c( "1 day","2 - 7 days","8 days - 1 month","> 1 month - 1 year","1 year","> 1 year - 5 years", "> 5 years"))

time_bin$time_bin <- factor(time_bin$time_bin, levels = c("< 1 day","1 day","2 - 7 days","8 days - 1 month","> 1 month - 1 year","1 year","> 1 year - 5 years"))

time_bin_plot = time_bin%>%
  filter(!is.na(horiz_bin),
         !is.na(time_bin))

times = c("< 1 day", "1 day","2 - 7 days","8 days - 1 month","> 1 month - 1 year","1 year","> 1 year - 5 years")
horiz = c("1 day","2 - 7 days","8 days - 1 month","> 1 month - 1 year","1 year","> 1 year - 5 years", "> 5 years")
fix = data.frame(horiz_bin = rep(times, length(horiz)), time_bin = rep(horiz, each = length(times)))

n = time_bin_plot%>%
  group_by(horiz_bin,time_bin)%>%
  summarise(ns = n())%>%
  mutate(color = ns>20)

jpeg("../Figures/timestep_heatmap.jpeg",res = 600,width = 6, height = 4, units = "in")
library("RColorBrewer")
cols <- brewer.pal(n = 9, name = "BuPu")
time_bin_plot%>%
  ggplot(aes(x = horiz_bin, y = time_bin), na.rm = T)+
  geom_bin2d()+
  xlab("Time horizon")+
  ylab("Time step")+
  scale_fill_gradientn(colors = cols)+
  scale_x_discrete(drop  =F)+
  scale_y_discrete(drop  =F)+
  geom_text(aes(label = ns, color = color), data = n, show.legend = F)+ #Can get rid of this by commenting out
  theme_light()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank())+
  scale_color_manual(values = c("gray40","gray90"))
dev.off()

jpeg("../Figures/timestep_heatmap_small.jpeg",res = 600,width = 3, height = 3, units = "in")
library("RColorBrewer")
cols <- brewer.pal(n = 9, name = "BuPu")
time_bin_plot%>%
  ggplot(aes(x = horiz_bin, y = time_bin), na.rm = T)+
  geom_bin2d()+
  xlab("Time horizon (days)")+
  ylab("Time step (days)")+
  scale_fill_gradientn(colors = cols)+
  scale_x_discrete(breaks = c( "1 day","2 - 7 days","8 days - 1 month","> 1 month - 1 year","1 year","> 1 year - 5 years","> 5 years"), labels = c("1","2 - 7","8 - 31 ","32 - 365","365","366 - 1825", ">1825"),drop  =F)+
  scale_y_discrete(breaks = c("< 1 day", "1 day","2 - 7 days","8 days - 1 month","> 1 month - 1 year","1 year","> 1 year - 5 years"), labels = c("< 1", "1","2 - 7","8 - 31 ","32 - 365","365","366 - 1825"),drop  =F)+
  geom_text(aes(label = ns, color = color), data = n, show.legend = F, size = 3)+ #Can get rid of this by commenting out
  theme_light()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        legend.position = "none")+
  scale_color_manual(values = c("gray40","gray100"))
dev.off()


nrow(time_bin%>%filter(horiz_bin %in% c("< 1 day", "1 day","2 - 7 days","8 days - 1 month","> 1 month - 1 year","1 year")))/nrow(time_bin%>%filter(!is.na(horiz_bin)))*100
nrow(time_bin%>%filter(horiz_bin %in% c("2 - 7 days"),time_bin %in% c("1 day")))/nrow(time_bin%>%filter(!is.na(horiz_bin)))*100
nrow(time_bin%>%filter(horiz_bin %in% c("1 year"),time_bin %in% c("1 year")))/nrow(time_bin%>%filter(!is.na(horiz_bin)))*100

summary(time_bin_plot$horiz_bin)
```